{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:00.952755400Z",
     "start_time": "2023-10-17T10:39:58.919754600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.functional as F\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:00.968767200Z",
     "start_time": "2023-10-17T10:40:00.955755400Z"
    }
   },
   "id": "3813e55320cad319"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 224, 224]), torch.float32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = read_image(\"./data/Pascal VOC 2012/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\")\n",
    "transform = transforms.RandomCrop(224)\n",
    "input = transform(input)\n",
    "input = transforms.functional.convert_image_dtype(input, torch.float)\n",
    "input.size(), input.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:01.939190200Z",
     "start_time": "2023-10-17T10:40:01.896185600Z"
    }
   },
   "id": "2cc7d44c17e683e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1000])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.VGG()\n",
    "model.eval()\n",
    "output = model(input.unsqueeze(0))\n",
    "output.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:04.044751200Z",
     "start_time": "2023-10-17T10:40:03.210742400Z"
    }
   },
   "id": "161c24d296819745"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "log_batch_inx = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:05.527746700Z",
     "start_time": "2023-10-17T10:40:05.507743900Z"
    }
   },
   "id": "428daaa2e4ba8554"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root=\"./data/MNIST\",\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True\n",
    "                            )\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True\n",
    "                          )\n",
    "\n",
    "test_data = datasets.MNIST(root=\"./data/MNIST\",\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True\n",
    "                           )\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True\n",
    "                         )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:06.854930Z",
     "start_time": "2023-10-17T10:40:06.801930300Z"
    }
   },
   "id": "17045d7d63ce64bf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:08.556178300Z",
     "start_time": "2023-10-17T10:40:08.544177900Z"
    }
   },
   "id": "90c37daf46845323"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 运行主训练循环，VGG过深无法完成\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 300 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.data.item()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b79f1ae5f2b84020"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        _, predictions = torch.max(output, dim=1)\n",
    "        num_correct += (predictions == labels).sum()\n",
    "        num_samples += predictions.size(0)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(torch.min(output))\n",
    "            show(data[0].view(-1, 28, 28))\n",
    "            print(output[0])\n",
    "            print(predictions[0], labels[0])\n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}')\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86b2799f23644b11"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input = read_image(\"./data/Pascal VOC 2012/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\")\n",
    "transform = transforms.RandomCrop(224)\n",
    "# input = transform(input)\n",
    "input = transforms.functional.convert_image_dtype(input, torch.float)\n",
    "# print(input.size(), input.dtype)\n",
    "model = models.FCN()\n",
    "model.eval()\n",
    "output = model(input.unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T10:40:40.989327500Z",
     "start_time": "2023-10-17T10:40:39.574288200Z"
    }
   },
   "id": "86c0c83263f638c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
